{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet --upgrade google-cloud-logging google_cloud_firestore google_cloud_aiplatform langchain langchain-google-vertexai langchain_community langchain_experimental pymupdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wcgdv9IdGFnN",
        "outputId": "813dfff8-7cc0-4908-ed0f-712c64c85084"
      },
      "id": "Wcgdv9IdGFnN",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.5/229.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.31.1 which is incompatible.\n",
            "tensorflow 2.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.31.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import vertexai\n",
        "import logging\n",
        "import google.cloud.logging\n",
        "from vertexai.language_models import TextEmbeddingModel\n",
        "from vertexai.generative_models import GenerativeModel\n",
        "\n",
        "import pickle\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "from langchain_google_vertexai import VertexAIEmbeddings\n",
        "from langchain_community.document_loaders import PyMuPDFLoader\n",
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "\n",
        "from google.cloud import firestore\n",
        "from google.cloud.firestore_v1.vector import Vector\n",
        "from google.cloud.firestore_v1.base_vector_query import DistanceMeasure"
      ],
      "metadata": {
        "id": "Jkfo6fsmGH5_"
      },
      "id": "Jkfo6fsmGH5_",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_ID = \"qwiklabs-gcp-03-1144253aecd8\"\n",
        "LOCATION = \"us-central1\"\n",
        "import vertexai\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)"
      ],
      "metadata": {
        "id": "JUUd8yECGIGf"
      },
      "id": "JUUd8yECGIGf",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_model = VertexAIEmbeddings(model_name=\"text-embedding-005\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuMjkmQRGIJf",
        "outputId": "ac07d8e6-2e96-4aa6-f9e8-ea901d0e41b3"
      },
      "id": "xuMjkmQRGIJf",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/vertexai/_model_garden/_model_garden_models.py:278: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
            "  warning_logs.show_deprecation_warning()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud storage cp gs://qwiklabs-gcp-03-1144253aecd8-bucket/embeddings.json ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTaiv7xQGIMW",
        "outputId": "ccfd359c-04ac-4add-e655-8b46bb5bf637"
      },
      "id": "MTaiv7xQGIMW",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying gs://qwiklabs-gcp-03-1144253aecd8-bucket/embeddings.json to file://./embeddings.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open(\"embeddings.json\", \"r\") as f:\n",
        "    precomputed = json.load(f)\n",
        "\n",
        "chunks = []\n",
        "embeddings = []\n",
        "\n",
        "for item in precomputed:\n",
        "    chunks.append(item[\"content\"]) # Extract the text chunk\n",
        "    embeddings.append(item[\"embedding\"]) # Extract the embedding vector"
      ],
      "metadata": {
        "id": "_TYBbKo7GIPL"
      },
      "id": "_TYBbKo7GIPL",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "id": "tE9tR5BYSVWOvS9EdINdKrVF",
      "metadata": {
        "tags": [],
        "id": "tE9tR5BYSVWOvS9EdINdKrVF"
      },
      "source": [
        "from google.cloud import firestore\n",
        "\n",
        "# Initialize Firestore client\n",
        "db = firestore.Client(project=PROJECT_ID)\n",
        "collection = db.collection(\"food_safety_chunks\")\n",
        "\n",
        "# Store each embedding and chunk\n",
        "for i, (embedding, chunk) in enumerate(zip(embeddings, chunks)):\n",
        "    doc = {\n",
        "        \"embedding\": embedding,\n",
        "        \"chunk\": chunk\n",
        "    }\n",
        "    collection.document(f\"chunk_{i}\").set(doc)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "def query_firestore(query_text):\n",
        "    model = TextEmbeddingModel.from_pretrained(\"text-embedding-005\")\n",
        "    query_embedding = model.get_embeddings([query_text])[0].values\n",
        "\n",
        "    docs = collection.stream()\n",
        "    chunks_data = [(doc.to_dict()[\"chunk\"], doc.to_dict()[\"embedding\"]) for doc in docs]\n",
        "\n",
        "    sims = [(chunk, cosine_similarity([query_embedding], [emb])[0][0]) for chunk, emb in chunks_data]\n",
        "    top_chunks = sorted(sims, key=lambda x: x[1], reverse=True)[:3]\n",
        "\n",
        "    return \"\\n\".join([chunk for chunk, _ in top_chunks])"
      ],
      "metadata": {
        "id": "FkX62s8JFf2Z"
      },
      "id": "FkX62s8JFf2Z",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What should you do if food is left out overnight?\"\n",
        "relevant_text = query_firestore(query)\n",
        "\n",
        "chat_model = GenerativeModel(\"gemini-2.0-flash\")  # Instantiate GenerativeModel directly\n",
        "chat = chat_model.start_chat()\n",
        "\n",
        "response = chat.send_message(\n",
        "    f\"Use the following to answer the question:\\n\\n{relevant_text}\\n\\nQuestion: {query}\"\n",
        ")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apHdfP6UFhvx",
        "outputId": "dadd14df-e79e-4b67-c573-2a0c3e521e36"
      },
      "id": "apHdfP6UFhvx",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/vertexai/_model_garden/_model_garden_models.py:278: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
            "  warning_logs.show_deprecation_warning()\n",
            "/usr/local/lib/python3.11/dist-packages/vertexai/generative_models/_generative_models.py:433: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
            "  warning_logs.show_deprecation_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on the provided information about food safety and proper storage, if food is left out overnight, you should **discard it**. The information emphasizes the importance of proper storage for safety and quality, implying that leaving food out at room temperature for an extended period (like overnight) compromises its safety and could lead to foodborne illnesses.\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "student-03-3e59618f623c (Aug 27, 2025, 4:02:04 PM)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
